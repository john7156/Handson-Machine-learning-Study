{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "TensorFlow 2.4 on Python 3.8 & CUDA 11.1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "04_핸즈온 머신러닝 모델 훈련.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BB8MB7d-Rglk"
      },
      "source": [
        "**4장 – 모델 훈련**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmVWt_U8Rgll"
      },
      "source": [
        "_이 노트북은 4장에 있는 모든 샘플 코드와 연습문제 해답을 가지고 있습니다._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JZd6b6kRglm"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/rickiepark/handson-ml2/blob/master/04_training_linear_models.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />구글 코랩에서 실행하기</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdk8ygoORglm"
      },
      "source": [
        "# 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gr64nSsvRglm"
      },
      "source": [
        "먼저 몇 개의 모듈을 임포트합니다. 맷플롯립 그래프를 인라인으로 출력하도록 만들고 그림을 저장하는 함수를 준비합니다. 또한 파이썬 버전이 3.5 이상인지 확인합니다(파이썬 2.x에서도 동작하지만 곧 지원이 중단되므로 파이썬 3을 사용하는 것이 좋습니다). 사이킷런 버전이 0.20 이상인지도 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jzd8pUJRgln"
      },
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"training_linear_models\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d4Oh6A4Rgln"
      },
      "source": [
        "# 정규 방정식을 사용한 선형 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et7Fywv0Rglo"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X = 2 * np.random.rand(100, 1) # 균등분포 0~2 난수, 100*1 크기의 행렬\n",
        "y = 4 + 3 * X + np.random.randn(100, 1) # 표준정규분포"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PldT9dHdRglo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "bda8ad13-857a-496b-8689-4cc128417de7"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.axis([0, 2, 0, 15])\n",
        "save_fig(\"generated_data_plot\")\n",
        "plt.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "그림 저장: generated_data_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63T7YfdSUlNu"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndd42ZtURglp"
      },
      "source": [
        "**식 4-4: 정규 방정식**\n",
        "\n",
        "$\\hat{\\boldsymbol{\\theta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMnVpl2RRglp"
      },
      "source": [
        "X_b = np.c_[np.ones((100, 1)), X]  # 모든 샘플에 x0 = 1을 추가합니다. # 열 방향으로 array끼리 합침.\n",
        "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1hT9Ew8Rglp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "387712cd-21c8-4317-8c34-606fa01678c2"
      },
      "source": [
        "theta_best"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.21509616],\n",
              "       [2.77011339]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLjTHDjtRglq"
      },
      "source": [
        "$\\hat{y} = \\mathbf{X} \\boldsymbol{\\hat{\\theta}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX1Bpi4qRglq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9e071de-42da-49b2-d9ea-37631788edca"
      },
      "source": [
        "X_new = np.array([[0], [2]])\n",
        "X_new_b = np.c_[np.ones((2, 1)), X_new]  # 모든 샘플에 x0 = 1을 추가합니다.\n",
        "y_predict = X_new_b.dot(theta_best)\n",
        "y_predict"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.21509616],\n",
              "       [9.75532293]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1dY6zhERglq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "8b2c6166-627a-466a-b345-859a30e9e28d"
      },
      "source": [
        "plt.plot(X_new, y_predict, \"r-\")\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.axis([0, 2, 0, 15])\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzbi0DtnWNx1"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbmBkwWPRglq"
      },
      "source": [
        "책에 있는 그림은 범례와 축 레이블이 있는 그래프입니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Arf6QH0Rglq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "outputId": "8c92f00f-e4be-4275-9f3b-5e23573f104f"
      },
      "source": [
        "plt.plot(X_new, y_predict, \"r-\", linewidth=2, label=\"Predictions\")\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.axis([0, 2, 0, 15])\n",
        "save_fig(\"linear_model_predictions_plot\")\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "그림 저장: linear_model_predictions_plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P178T-0QRglq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537396f1-ed94-49b4-f0a4-39190a9255ca"
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X, y)\n",
        "lin_reg.intercept_, lin_reg.coef_"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.21509616]), array([[2.77011339]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJOHF0eXWoH2"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97ZLIh8pRglr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e20789f9-ca4d-483f-d58a-0073801cc66a"
      },
      "source": [
        "lin_reg.predict(X_new)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.21509616],\n",
              "       [9.75532293]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlZSxu-FW6nM"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PstdLKBjRglr"
      },
      "source": [
        "`LinearRegression` 클래스는 `scipy.linalg.lstsq()` 함수(\"least squares\"의 약자)를 사용하므로 이 함수를 직접 사용할 수 있습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEVj8KY8Rglr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c43500-1dd5-4525-b581-e61d071957bf"
      },
      "source": [
        "# 싸이파이 lstsq() 함수를 사용하려면 scipy.linalg.lstsq(X_b, y)와 같이 씁니다.\n",
        "theta_best_svd, residuals, rank, s = np.linalg.lstsq(X_b, y, rcond=1e-6)\n",
        "theta_best_svd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.21509616],\n",
              "       [2.77011339]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRFbmXsvXC7r"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Ur5X_gRglr"
      },
      "source": [
        "이 함수는 $\\mathbf{X}^+\\mathbf{y}$을 계산합니다. $\\mathbf{X}^{+}$는 $\\mathbf{X}$의 _유사역행렬_ (pseudoinverse)입니다(Moore–Penrose 유사역행렬입니다). `np.linalg.pinv()`을 사용해서 유사역행렬을 직접 계산할 수 있습니다:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG_2g2qYRglr"
      },
      "source": [
        "$\\boldsymbol{\\hat{\\theta}} = \\mathbf{X}^{-1}\\hat{y}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9roOlqNhRglr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5e95bf-816b-486e-d850-762db97e0e38"
      },
      "source": [
        "np.linalg.pinv(X_b).dot(y)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.21509616],\n",
              "       [2.77011339]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RChHa2ZWRglr"
      },
      "source": [
        "# 배치 경사 하강법을 사용한 선형 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYOp0XPPYZ_f"
      },
      "source": [
        "전체 데이터에서 비용 함수를 최소화(기울기가 0)하기 위해 반복적으로 모델 파라미터(theta)를 조정\n",
        "\n",
        "임의의 학습 스텝(학습률)에 따라 최솟값을 구해가는 과정\n",
        "\n",
        "\n",
        "학습 스텝이 너무 크면 최솟값을 건너 뛰고\n",
        "\n",
        "학습 스텝이 너무 작으면 학습 시간이 너무 오래 걸리는 단점\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "단점 \n",
        "\n",
        " \n",
        " 최솟값이 아닌 극솟값을 최솟값으로 판단할 수도 있음.\n",
        "\n",
        " 최솟값이 아닌 기울기가 0인 지점을 최솟값으로 판단할 수도 있음.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTiy_rvRgls"
      },
      "source": [
        "**식 4-6: 비용 함수의 그레이디언트 벡터**\n",
        "\n",
        "$\n",
        "\\dfrac{\\partial}{\\partial \\boldsymbol{\\theta}} \\text{MSE}(\\boldsymbol{\\theta})\n",
        " = \\dfrac{2}{m} \\mathbf{X}^T (\\mathbf{X} \\boldsymbol{\\theta} - \\mathbf{y})\n",
        "$\n",
        "\n",
        "**식 4-7: 경사 하강법의 스텝**\n",
        "\n",
        "$\n",
        "\\boldsymbol{\\theta}^{(\\text{next step})} = \\boldsymbol{\\theta} - \\eta \\dfrac{\\partial}{\\partial \\boldsymbol{\\theta}} \\text{MSE}(\\boldsymbol{\\theta})\n",
        "$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHlT-otWRgls"
      },
      "source": [
        "eta = 0.1  # 학습률\n",
        "n_iterations = 1000\n",
        "m = 100\n",
        "\n",
        "theta = np.random.randn(2,1)  # 랜덤 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
        "    theta = theta - eta * gradients"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTCV6-ENRgls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "841c47a4-b651-4afb-df42-ca1091667dbe"
      },
      "source": [
        "theta"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.21509616],\n",
              "       [2.77011339]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiD1bL8HRgls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce0e2d8-94fa-45ff-d0a8-13fb72aae5c1"
      },
      "source": [
        "X_new_b.dot(theta)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.21509616],\n",
              "       [9.75532293]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0VnCPs1Rgls"
      },
      "source": [
        "theta_path_bgd = []\n",
        "\n",
        "def plot_gradient_descent(theta, eta, theta_path=None):\n",
        "    m = len(X_b)\n",
        "    plt.plot(X, y, \"b.\")\n",
        "    n_iterations = 1000\n",
        "    for iteration in range(n_iterations):\n",
        "        if iteration < 10:\n",
        "            y_predict = X_new_b.dot(theta)\n",
        "            style = \"b-\" if iteration > 0 else \"r--\"\n",
        "            plt.plot(X_new, y_predict, style)\n",
        "        gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
        "        theta = theta - eta * gradients\n",
        "        if theta_path is not None:\n",
        "            theta_path.append(theta)\n",
        "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "    plt.axis([0, 2, 0, 15])\n",
        "    plt.title(r\"$\\eta = {}$\".format(eta), fontsize=16)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs8oS9m4Rgls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52318f3-fc3b-4477-fede-8024140b9085"
      },
      "source": [
        "np.random.seed(42)\n",
        "theta = np.random.randn(2,1)  # random initialization\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(131); plot_gradient_descent(theta, eta=0.02)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.subplot(132); plot_gradient_descent(theta, eta=0.1, theta_path=theta_path_bgd)\n",
        "plt.subplot(133); plot_gradient_descent(theta, eta=0.5)\n",
        "\n",
        "save_fig(\"gradient_descent_plot\")\n",
        "plt.show()\n",
        "# 적절한 학습률이 중요!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "그림 저장: gradient_descent_plot\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zytqHoJuRgls"
      },
      "source": [
        "# 확률적 경사 하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gviA_IjJa7zy"
      },
      "source": [
        "전체 데이터에서 일부만 활용\n",
        "\n",
        "에포크(큰 반복) 시작\n",
        "\n",
        " - 훈련 세트 시작\n",
        "   1. 훈련 세트에서 샘플 하나 꺼내기\n",
        "   2. 경사 하강법 수행\n",
        "   3. 모델 파라미터 수정\n",
        "   4. 수정\n",
        "  - 반복\n",
        " - 종료"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVfoz6wvRgls"
      },
      "source": [
        "theta_path_sgd = []\n",
        "m = len(X_b)\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYqYWbFeRglt"
      },
      "source": [
        "n_epochs = 50\n",
        "t0, t1 = 5, 50  # 학습 스케줄 하이퍼파라미터\n",
        "\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "theta = np.random.randn(2,1)  # 랜덤 초기화\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for i in range(m):\n",
        "        if epoch == 0 and i < 20:                    # 책에는 없음\n",
        "            y_predict = X_new_b.dot(theta)           # 책에는 없음\n",
        "            style = \"b-\" if i > 0 else \"r--\"         # 책에는 없음\n",
        "            plt.plot(X_new, y_predict, style)        # 책에는 없음\n",
        "        random_index = np.random.randint(m)\n",
        "        xi = X_b[random_index:random_index+1]\n",
        "        yi = y[random_index:random_index+1]\n",
        "        gradients = 2 * xi.T.dot(xi.dot(theta) - yi)\n",
        "        eta = learning_schedule(epoch * m + i)\n",
        "        theta = theta - eta * gradients\n",
        "        theta_path_sgd.append(theta)                 # 책에는 없음\n",
        "\n",
        "plt.plot(X, y, \"b.\")                                 # 책에는 없음\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)                     # 책에는 없음\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)           # 책에는 없음\n",
        "plt.axis([0, 2, 0, 15])                              # 책에는 없음\n",
        "save_fig(\"sgd_plot\")                                 # 책에는 없음\n",
        "plt.show()                                           # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3zpiDeJDRglt"
      },
      "source": [
        "theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApUGGdN3Rglt"
      },
      "source": [
        "from sklearn.linear_model import SGDRegressor # 확률적 경사 하강법\n",
        "\n",
        "sgd_reg = SGDRegressor(max_iter=1000, tol=1e-3, penalty=None, eta0=0.1, random_state=42)\n",
        "# max_iter : 에포크 , tol = 1e-3 : tol가 1e-3보다 크지 않으면 최적인 모델, eta0 : 학습률 \n",
        "sgd_reg.fit(X, y.ravel())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uL_Q6iqnceFP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xs8bUQdRglt"
      },
      "source": [
        "sgd_reg.intercept_, sgd_reg.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUYRvt42Rglt"
      },
      "source": [
        "# 미니배치 경사 하강법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e1_B6TmhPbm"
      },
      "source": [
        "전체 데이터를 batch_size개씩 나눠 각각 경사하강법 수행\n",
        "\n",
        "batch_size는 사용자가 설정\n",
        "\n",
        "계산량이 배치 경사하강법보다 적음\n",
        "\n",
        "지역 최솟값을 찾을 확률을 줄일 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8nirHkIRglt"
      },
      "source": [
        "theta_path_mgd = []\n",
        "\n",
        "n_iterations = 50\n",
        "minibatch_size = 20\n",
        "\n",
        "np.random.seed(42)\n",
        "theta = np.random.randn(2,1)  # 랜덤 초기화\n",
        "\n",
        "t0, t1 = 200, 1000\n",
        "def learning_schedule(t):\n",
        "    return t0 / (t + t1)\n",
        "\n",
        "t = 0\n",
        "for epoch in range(n_iterations):\n",
        "    shuffled_indices = np.random.permutation(m)\n",
        "    X_b_shuffled = X_b[shuffled_indices]\n",
        "    y_shuffled = y[shuffled_indices]\n",
        "    for i in range(0, m, minibatch_size):\n",
        "        t += 1\n",
        "        xi = X_b_shuffled[i:i+minibatch_size]\n",
        "        yi = y_shuffled[i:i+minibatch_size]\n",
        "        gradients = 2/minibatch_size * xi.T.dot(xi.dot(theta) - yi)\n",
        "        eta = learning_schedule(t)\n",
        "        theta = theta - eta * gradients\n",
        "        theta_path_mgd.append(theta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMsBXVDaRglt"
      },
      "source": [
        "theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqvnyNCSRglt"
      },
      "source": [
        "theta_path_bgd = np.array(theta_path_bgd)\n",
        "theta_path_sgd = np.array(theta_path_sgd)\n",
        "theta_path_mgd = np.array(theta_path_mgd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUJVq2sRRglt"
      },
      "source": [
        "plt.figure(figsize=(7,4))\n",
        "plt.plot(theta_path_sgd[:, 0], theta_path_sgd[:, 1], \"r-s\", linewidth=1, label=\"Stochastic\")\n",
        "plt.plot(theta_path_mgd[:, 0], theta_path_mgd[:, 1], \"g-+\", linewidth=2, label=\"Mini-batch\")\n",
        "plt.plot(theta_path_bgd[:, 0], theta_path_bgd[:, 1], \"b-o\", linewidth=3, label=\"Batch\")\n",
        "plt.legend(loc=\"upper left\", fontsize=16)\n",
        "plt.xlabel(r\"$\\theta_0$\", fontsize=20)\n",
        "plt.ylabel(r\"$\\theta_1$   \", fontsize=20, rotation=0)\n",
        "plt.axis([2.5, 4.5, 2.3, 3.9])\n",
        "save_fig(\"gradient_descent_paths_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92hIiDw2Rglu"
      },
      "source": [
        "# 다항 회귀"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu5H5asyRglu"
      },
      "source": [
        "import numpy as np\n",
        "import numpy.random as rnd\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJheMR9SRglu"
      },
      "source": [
        "m = 100\n",
        "X = 6 * np.random.rand(m, 1) - 3\n",
        "y = 0.5 * X**2 + X + 2 + np.random.randn(m, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYTv5Mc7Rglu"
      },
      "source": [
        "plt.plot(X, y, \"b.\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "save_fig(\"quadratic_data_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNuAJ7tbRglu"
      },
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures # 데이터를 다항식 형태로 변환\n",
        "poly_features = PolynomialFeatures(degree=2, include_bias=False) # 2차 다항식, 편차x\n",
        "X_poly = poly_features.fit_transform(X)\n",
        "X[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1m8UxgKn9oP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPQkgC8nRglu"
      },
      "source": [
        "X_poly[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0ZHdhwtRglu"
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_poly, y)\n",
        "lin_reg.intercept_, lin_reg.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcmK5SH8Rglv"
      },
      "source": [
        "X_new=np.linspace(-3, 3, 100).reshape(100, 1)\n",
        "X_new_poly = poly_features.transform(X_new)\n",
        "y_new = lin_reg.predict(X_new_poly)\n",
        "plt.plot(X, y, \"b.\")\n",
        "plt.plot(X_new, y_new, \"r-\", linewidth=2, label=\"Predictions\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "save_fig(\"quadratic_predictions_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RBQSde8Rglv"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "for style, width, degree in ((\"g-\", 1, 300), (\"b--\", 2, 2), (\"r-+\", 2, 1)):\n",
        "    polybig_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
        "    std_scaler = StandardScaler()\n",
        "    lin_reg = LinearRegression()\n",
        "    polynomial_regression = Pipeline([\n",
        "            (\"poly_features\", polybig_features),\n",
        "            (\"std_scaler\", std_scaler),\n",
        "            (\"lin_reg\", lin_reg),\n",
        "        ])\n",
        "    polynomial_regression.fit(X, y)\n",
        "    y_newbig = polynomial_regression.predict(X_new)\n",
        "    plt.plot(X_new, y_newbig, style, label=str(degree), linewidth=width)\n",
        "\n",
        "plt.plot(X, y, \"b.\", linewidth=3)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.axis([-3, 3, 0, 10])\n",
        "save_fig(\"high_degree_polynomials_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7h0d4A5Rglv"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def plot_learning_curves(model, X, y):\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "    train_errors, val_errors = [], []\n",
        "    for m in range(1, len(X_train)):\n",
        "        model.fit(X_train[:m], y_train[:m])\n",
        "        y_train_predict = model.predict(X_train[:m])\n",
        "        y_val_predict = model.predict(X_val)\n",
        "        train_errors.append(mean_squared_error(y_train[:m], y_train_predict))\n",
        "        val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
        "\n",
        "    plt.plot(np.sqrt(train_errors), \"r-+\", linewidth=2, label=\"train\")\n",
        "    plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"val\")\n",
        "    plt.legend(loc=\"upper right\", fontsize=14)   # 책에는 없음\n",
        "    plt.xlabel(\"Training set size\", fontsize=14) # 책에는 없음\n",
        "    plt.ylabel(\"RMSE\", fontsize=14)              # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeRH0ipGRglv"
      },
      "source": [
        "lin_reg = LinearRegression()\n",
        "plot_learning_curves(lin_reg, X, y)\n",
        "plt.axis([0, 80, 0, 3])                         # 책에는 없음\n",
        "save_fig(\"underfitting_learning_curves_plot\")   # 책에는 없음\n",
        "plt.show()                                      # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHUx7r3aRglv"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "polynomial_regression = Pipeline([\n",
        "        (\"poly_features\", PolynomialFeatures(degree=10, include_bias=False)),\n",
        "        (\"lin_reg\", LinearRegression()),\n",
        "    ])\n",
        "\n",
        "plot_learning_curves(polynomial_regression, X, y)\n",
        "plt.axis([0, 80, 0, 3])           # 책에는 없음\n",
        "save_fig(\"learning_curves_plot\")  # 책에는 없음\n",
        "plt.show()                        # 책에는 없음"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C49KE9KRglx"
      },
      "source": [
        "# 규제가 있는 모델"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuXx7cRuRglx"
      },
      "source": [
        "np.random.seed(42)\n",
        "m = 20\n",
        "X = 3 * np.random.rand(m, 1)\n",
        "y = 1 + 0.5 * X + np.random.randn(m, 1) / 1.5\n",
        "X_new = np.linspace(0, 3, 100).reshape(100, 1) # [0,3]에서 100개의 데이터"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qrcU9Z4Rglx"
      },
      "source": [
        "**식 4-8: 릿지 회귀의 비용 함수**\n",
        "\n",
        "$\n",
        "J(\\boldsymbol{\\theta}) = \\text{MSE}(\\boldsymbol{\\theta}) + \\alpha \\dfrac{1}{2}\\sum\\limits_{i=1}^{n}{\\theta_i}^2\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwJUnKEZRglx"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "ridge_reg = Ridge(alpha=1, solver=\"cholesky\", random_state=42) # alpha : 모델에 규제를 가하는 하이퍼파라미터 # 상수항은 규제x\n",
        "ridge_reg.fit(X, y)\n",
        "ridge_reg.predict([[1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFHzlO2-sT_i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbfz3OI_Rglx"
      },
      "source": [
        "ridge_reg = Ridge(alpha=1, solver=\"sag\", random_state=42)\n",
        "ridge_reg.fit(X, y)\n",
        "ridge_reg.predict([[1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGkUVECrshGX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NunAZF3fRglx"
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "def plot_model(model_class, polynomial, alphas, **model_kargs):\n",
        "    for alpha, style in zip(alphas, (\"b-\", \"g--\", \"r:\")):\n",
        "        model = model_class(alpha, **model_kargs) if alpha > 0 else LinearRegression()\n",
        "        if polynomial:\n",
        "            model = Pipeline([\n",
        "                    (\"poly_features\", PolynomialFeatures(degree=10, include_bias=False)),\n",
        "                    (\"std_scaler\", StandardScaler()),\n",
        "                    (\"regul_reg\", model),\n",
        "                ])\n",
        "        model.fit(X, y)\n",
        "        y_new_regul = model.predict(X_new)\n",
        "        lw = 2 if alpha > 0 else 1\n",
        "        plt.plot(X_new, y_new_regul, style, linewidth=lw, label=r\"$\\alpha = {}$\".format(alpha))\n",
        "    plt.plot(X, y, \"b.\", linewidth=3)\n",
        "    plt.legend(loc=\"upper left\", fontsize=15)\n",
        "    plt.xlabel(\"$x_1$\", fontsize=18)\n",
        "    plt.axis([0, 3, 0, 4])\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(121)\n",
        "plot_model(Ridge, polynomial=False, alphas=(0, 10, 100), random_state=42)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.subplot(122)\n",
        "plot_model(Ridge, polynomial=True, alphas=(0, 10**-5, 1), random_state=42)\n",
        "\n",
        "save_fig(\"ridge_regression_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTSJq3XCRglx"
      },
      "source": [
        "**노트**: 향후 버전이 바뀌더라도 동일한 결과를 만들기 위해 사이킷런 0.21 버전의 기본값인 `max_iter=1000`과 `tol=1e-3`으로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SX9Z81uRgly"
      },
      "source": [
        "sgd_reg = SGDRegressor(penalty=\"l2\", max_iter=1000, tol=1e-3, random_state=42) # penalty = 'l2' : ridge 모델의 손실함수\n",
        "sgd_reg.fit(X, y.ravel())\n",
        "sgd_reg.predict([[1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXl2V4Ottd8i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Xydb_KRgly"
      },
      "source": [
        "**식 4-10: 라쏘 회귀의 비용 함수**\n",
        "\n",
        "$\n",
        "J(\\boldsymbol{\\theta}) = \\text{MSE}(\\boldsymbol{\\theta}) + \\alpha \\sum\\limits_{i=1}^{n}\\left| \\theta_i \\right|\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTrq86IzRgly"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(121)\n",
        "plot_model(Lasso, polynomial=False, alphas=(0, 0.1, 1), random_state=42)\n",
        "plt.ylabel(\"$y$\", rotation=0, fontsize=18)\n",
        "plt.subplot(122)\n",
        "plot_model(Lasso, polynomial=True, alphas=(0, 10**-7, 1), random_state=42)\n",
        "\n",
        "save_fig(\"lasso_regression_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDgAF9hxuIhu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UeRDNf90Rgly"
      },
      "source": [
        "from sklearn.linear_model import Lasso\n",
        "lasso_reg = Lasso(alpha=0.1)\n",
        "lasso_reg.fit(X, y)\n",
        "lasso_reg.predict([[1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntbQcFKPuUtj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlltBm4kRgly"
      },
      "source": [
        "**식 4-12: 엘라스틱넷 비용 함수**\n",
        "\n",
        "$\n",
        "J(\\boldsymbol{\\theta}) = \\text{MSE}(\\boldsymbol{\\theta}) + r \\alpha \\sum\\limits_{i=1}^{n}\\left| \\theta_i \\right| + \\dfrac{1 - r}{2} \\alpha \\sum\\limits_{i=1}^{n}{{\\theta_i}^2}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4saQtYKRgly"
      },
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "\n",
        "# Lasso == ElasticNet(l1_ratio=1.0)\n",
        "elastic_net = ElasticNet(alpha=0.1, l1_ratio=0.5, random_state=42) # l1_ratio : r\n",
        "elastic_net.fit(X, y)\n",
        "elastic_net.predict([[1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF7hqypVucqQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZgWbYS6Rgly"
      },
      "source": [
        "np.random.seed(42)\n",
        "m = 100\n",
        "X = 6 * np.random.rand(m, 1) - 3\n",
        "y = 2 + X + 0.5 * X**2 + np.random.randn(m, 1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:50], y[:50].ravel(), test_size=0.5, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auZQNc_tRgly"
      },
      "source": [
        "조기 종료 예제:\n",
        "\n",
        "조기종료란 경사하강법과 같이 반복학습 알고리즘을 규제하는 방법으로, 검증 에러가 최솟값에 도달하면 훈련을 중지(조기 종료)시키는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "rTDmSyzTRgly"
      },
      "source": [
        "from copy import deepcopy\n",
        "\n",
        "poly_scaler = Pipeline([\n",
        "        (\"poly_features\", PolynomialFeatures(degree=90, include_bias=False)),\n",
        "        (\"std_scaler\", StandardScaler())\n",
        "    ])\n",
        "\n",
        "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
        "X_val_poly_scaled = poly_scaler.transform(X_val)\n",
        "\n",
        "sgd_reg = SGDRegressor(max_iter=1, tol=-np.infty, warm_start=True,\n",
        "                       penalty=None, learning_rate=\"constant\", eta0=0.0005, random_state=42)\n",
        "\n",
        "minimum_val_error = float(\"inf\")\n",
        "best_epoch = None\n",
        "best_model = None\n",
        "for epoch in range(1000):\n",
        "    sgd_reg.fit(X_train_poly_scaled, y_train)  # 중지된 곳에서 다시 시작합니다\n",
        "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
        "    val_error = mean_squared_error(y_val, y_val_predict)\n",
        "    if val_error < minimum_val_error:\n",
        "        minimum_val_error = val_error\n",
        "        best_epoch = epoch\n",
        "        best_model = deepcopy(sgd_reg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgWe7tJWRglz"
      },
      "source": [
        "그래프를 그립니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIGrYaxdRglz"
      },
      "source": [
        "sgd_reg = SGDRegressor(max_iter=1, tol=-np.infty, warm_start=True,\n",
        "                       penalty=None, learning_rate=\"constant\", eta0=0.0005, random_state=42)\n",
        "\n",
        "n_epochs = 500\n",
        "train_errors, val_errors = [], []\n",
        "for epoch in range(n_epochs):\n",
        "    sgd_reg.fit(X_train_poly_scaled, y_train)\n",
        "    y_train_predict = sgd_reg.predict(X_train_poly_scaled)\n",
        "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
        "    train_errors.append(mean_squared_error(y_train, y_train_predict))\n",
        "    val_errors.append(mean_squared_error(y_val, y_val_predict))\n",
        "\n",
        "best_epoch = np.argmin(val_errors)\n",
        "best_val_rmse = np.sqrt(val_errors[best_epoch])\n",
        "\n",
        "plt.annotate('Best model',\n",
        "             xy=(best_epoch, best_val_rmse),\n",
        "             xytext=(best_epoch, best_val_rmse + 1),\n",
        "             ha=\"center\",\n",
        "             arrowprops=dict(facecolor='black', shrink=0.05),\n",
        "             fontsize=16,\n",
        "            )\n",
        "\n",
        "best_val_rmse -= 0.03  # just to make the graph look better\n",
        "plt.plot([0, n_epochs], [best_val_rmse, best_val_rmse], \"k:\", linewidth=2)\n",
        "plt.plot(np.sqrt(val_errors), \"b-\", linewidth=3, label=\"Validation set\")\n",
        "plt.plot(np.sqrt(train_errors), \"r--\", linewidth=2, label=\"Training set\")\n",
        "plt.legend(loc=\"upper right\", fontsize=14)\n",
        "plt.xlabel(\"Epoch\", fontsize=14)\n",
        "plt.ylabel(\"RMSE\", fontsize=14)\n",
        "save_fig(\"early_stopping_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTFNudnFRglz"
      },
      "source": [
        "best_epoch, minimum_val_error ,best_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJAgQZmURglz"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqvlfurbRglz"
      },
      "source": [
        "t1a, t1b, t2a, t2b = -1, 3, -1.5, 1.5\n",
        "\n",
        "t1s = np.linspace(t1a, t1b, 500)\n",
        "t2s = np.linspace(t2a, t2b, 500)\n",
        "t1, t2 = np.meshgrid(t1s, t2s)\n",
        "T = np.c_[t1.ravel(), t2.ravel()]\n",
        "Xr = np.array([[1, 1], [1, -1], [1, 0.5]])\n",
        "yr = 2 * Xr[:, :1] + 0.5 * Xr[:, 1:]\n",
        "\n",
        "J = (1/len(Xr) * np.sum((T.dot(Xr.T) - yr.T)**2, axis=1)).reshape(t1.shape)\n",
        "\n",
        "N1 = np.linalg.norm(T, ord=1, axis=1).reshape(t1.shape)\n",
        "N2 = np.linalg.norm(T, ord=2, axis=1).reshape(t1.shape)\n",
        "\n",
        "t_min_idx = np.unravel_index(np.argmin(J), J.shape)\n",
        "t1_min, t2_min = t1[t_min_idx], t2[t_min_idx]\n",
        "\n",
        "t_init = np.array([[0.25], [-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G22bcmFXRglz"
      },
      "source": [
        "def bgd_path(theta, X, y, l1, l2, core = 1, eta = 0.05, n_iterations = 200):\n",
        "    path = [theta]\n",
        "    for iteration in range(n_iterations):\n",
        "        gradients = core * 2/len(X) * X.T.dot(X.dot(theta) - y) + l1 * np.sign(theta) + l2 * theta\n",
        "        theta = theta - eta * gradients\n",
        "        path.append(theta)\n",
        "    return np.array(path)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(10.1, 8))\n",
        "for i, N, l1, l2, title in ((0, N1, 2., 0, \"Lasso\"), (1, N2, 0,  2., \"Ridge\")):\n",
        "    JR = J + l1 * N1 + l2 * 0.5 * N2**2\n",
        "    \n",
        "    tr_min_idx = np.unravel_index(np.argmin(JR), JR.shape)\n",
        "    t1r_min, t2r_min = t1[tr_min_idx], t2[tr_min_idx]\n",
        "\n",
        "    levelsJ=(np.exp(np.linspace(0, 1, 20)) - 1) * (np.max(J) - np.min(J)) + np.min(J)\n",
        "    levelsJR=(np.exp(np.linspace(0, 1, 20)) - 1) * (np.max(JR) - np.min(JR)) + np.min(JR)\n",
        "    levelsN=np.linspace(0, np.max(N), 10)\n",
        "    \n",
        "    path_J = bgd_path(t_init, Xr, yr, l1=0, l2=0)\n",
        "    path_JR = bgd_path(t_init, Xr, yr, l1, l2)\n",
        "    path_N = bgd_path(np.array([[2.0], [0.5]]), Xr, yr, np.sign(l1)/3, np.sign(l2), core=0)\n",
        "\n",
        "    ax = axes[i, 0]\n",
        "    ax.grid(True)\n",
        "    ax.axhline(y=0, color='k')\n",
        "    ax.axvline(x=0, color='k')\n",
        "    ax.contourf(t1, t2, N / 2., levels=levelsN)\n",
        "    ax.plot(path_N[:, 0], path_N[:, 1], \"y--\")\n",
        "    ax.plot(0, 0, \"ys\")\n",
        "    ax.plot(t1_min, t2_min, \"ys\")\n",
        "    ax.set_title(r\"$\\ell_{}$ penalty\".format(i + 1), fontsize=16)\n",
        "    ax.axis([t1a, t1b, t2a, t2b])\n",
        "    if i == 1:\n",
        "        ax.set_xlabel(r\"$\\theta_1$\", fontsize=16)\n",
        "    ax.set_ylabel(r\"$\\theta_2$\", fontsize=16, rotation=0)\n",
        "\n",
        "    ax = axes[i, 1]\n",
        "    ax.grid(True)\n",
        "    ax.axhline(y=0, color='k')\n",
        "    ax.axvline(x=0, color='k')\n",
        "    ax.contourf(t1, t2, JR, levels=levelsJR, alpha=0.9)\n",
        "    ax.plot(path_JR[:, 0], path_JR[:, 1], \"w-o\")\n",
        "    ax.plot(path_N[:, 0], path_N[:, 1], \"y--\")\n",
        "    ax.plot(0, 0, \"ys\")\n",
        "    ax.plot(t1_min, t2_min, \"ys\")\n",
        "    ax.plot(t1r_min, t2r_min, \"rs\")\n",
        "    ax.set_title(title, fontsize=16)\n",
        "    ax.axis([t1a, t1b, t2a, t2b])\n",
        "    if i == 1:\n",
        "        ax.set_xlabel(r\"$\\theta_1$\", fontsize=16)\n",
        "\n",
        "save_fig(\"lasso_vs_ridge_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GW9Et5tRglz"
      },
      "source": [
        "# 로지스틱 회귀"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYRXxxIe0wvN"
      },
      "source": [
        "0보다 크면 양성 클래스\n",
        "\n",
        "\n",
        "0보다 작으면 음성 클래스로 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfcS6G3vRglz"
      },
      "source": [
        "t = np.linspace(-10, 10, 100)\n",
        "sig = 1 / (1 + np.exp(-t))\n",
        "plt.figure(figsize=(9, 3))\n",
        "plt.plot([-10, 10], [0, 0], \"k-\")\n",
        "plt.plot([-10, 10], [0.5, 0.5], \"k:\")\n",
        "plt.plot([-10, 10], [1, 1], \"k:\")\n",
        "plt.plot([0, 0], [-1.1, 1.1], \"k-\")\n",
        "plt.plot(t, sig, \"b-\", linewidth=2, label=r\"$\\sigma(t) = \\frac{1}{1 + e^{-t}}$\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.legend(loc=\"upper left\", fontsize=20)\n",
        "plt.axis([-10, 10, -0.1, 1.1])\n",
        "save_fig(\"logistic_function_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22VVok5O1C7p"
      },
      "source": [
        "확률값이 0.5보다 크면 양성 클래스\n",
        "\n",
        "확률값이 0.5보다 작으면 음성 클래스"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB5e9E8WRglz"
      },
      "source": [
        "**식 4-16: 하나의 훈련 샘플에 대한 비용 함수**\n",
        "\n",
        "$\n",
        "c(\\boldsymbol{\\theta}) =\n",
        "\\begin{cases}\n",
        "  -\\log(\\hat{p}) & \\text{if } y = 1, \\\\\n",
        "  -\\log(1 - \\hat{p}) & \\text{if } y = 0.\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "\n",
        "**식 4-17: 로지스틱 회귀 비용 함수(로그 손실)**\n",
        "\n",
        "$\n",
        "J(\\boldsymbol{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}\n",
        "$\n",
        "\n",
        "\n",
        "**식 4-18: 로지스틱 비용 함수의 편도 함수**\n",
        "\n",
        "$\n",
        "\\dfrac{\\partial}{\\partial \\theta_j} \\text{J}(\\boldsymbol{\\theta}) = \\dfrac{1}{m}\\sum\\limits_{i=1}^{m}\\left(\\mathbf{\\sigma(\\boldsymbol{\\theta}}^T \\mathbf{x}^{(i)}) - y^{(i)}\\right)\\, x_j^{(i)}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kjlP112Rgl0"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "list(iris.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7L9gea7Rgl0"
      },
      "source": [
        "print(iris.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B8EC5_nRgl0"
      },
      "source": [
        "X = iris[\"data\"][:, 3:]  # 꽃잎 너비\n",
        "y = (iris[\"target\"] == 2).astype(np.int)  # Iris virginica이면 1 아니면 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSL3DVfk29zr"
      },
      "source": [
        "np.unique(iris.target,return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CloXvi7hRgl0"
      },
      "source": [
        "**노트**: 향후 버전이 바뀌더라도 동일한 결과를 만들기 위해 사이킷런 0.22 버전의 기본값인 `solver=\"lbfgs\"`로 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCQ_YmyjRgl0"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "log_reg = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
        "log_reg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Md9jhD0A3UOW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bYtn0mERgl0"
      },
      "source": [
        "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
        "y_proba = log_reg.predict_proba(X_new)\n",
        "\n",
        "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris virginica\")\n",
        "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris virginica\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saEj2HIZRgl0"
      },
      "source": [
        "책에 실린 그림은 조금 더 예쁘게 꾸몄습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIhG22Q7Rgl0"
      },
      "source": [
        "X_new = np.linspace(0, 3, 1000).reshape(-1, 1)\n",
        "y_proba = log_reg.predict_proba(X_new)\n",
        "decision_boundary = X_new[y_proba[:, 1] >= 0.5][0]\n",
        "\n",
        "plt.figure(figsize=(8, 3))\n",
        "plt.plot(X[y==0], y[y==0], \"bs\")\n",
        "plt.plot(X[y==1], y[y==1], \"g^\")\n",
        "plt.plot([decision_boundary, decision_boundary], [-1, 2], \"k:\", linewidth=2)\n",
        "plt.plot(X_new, y_proba[:, 1], \"g-\", linewidth=2, label=\"Iris virginica\")\n",
        "plt.plot(X_new, y_proba[:, 0], \"b--\", linewidth=2, label=\"Not Iris virginica\")\n",
        "plt.text(decision_boundary+0.02, 0.15, \"Decision  boundary\", fontsize=14, color=\"k\", ha=\"center\")\n",
        "plt.arrow(decision_boundary, 0.08, -0.3, 0, head_width=0.05, head_length=0.1, fc='b', ec='b')\n",
        "plt.arrow(decision_boundary, 0.92, 0.3, 0, head_width=0.05, head_length=0.1, fc='g', ec='g')\n",
        "plt.xlabel(\"Petal width (cm)\", fontsize=14)\n",
        "plt.ylabel(\"Probability\", fontsize=14)\n",
        "plt.legend(loc=\"center left\", fontsize=14)\n",
        "plt.axis([0, 3, -0.02, 1.02])\n",
        "save_fig(\"logistic_regression_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpbs0e7sRgl0"
      },
      "source": [
        "decision_boundary # 1.66보다 크면 양성 -> virginica\n",
        "                  # 1.66보다 작거나 같으면 음성"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_lk5ukRRgl0"
      },
      "source": [
        "log_reg.predict([[1.7], [1.5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4w_tmRsoRgl0"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X = iris[\"data\"][:, (2, 3)]  # petal length, petal width\n",
        "y = (iris[\"target\"] == 2).astype(np.int)\n",
        "\n",
        "log_reg = LogisticRegression(solver=\"lbfgs\", C=10**10, random_state=42)\n",
        "log_reg.fit(X, y)\n",
        "\n",
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(2.9, 7, 500).reshape(-1, 1),\n",
        "        np.linspace(0.8, 2.7, 200).reshape(-1, 1),\n",
        "    )\n",
        "# meshgrid : 1차원 좌표 배열에서 n차원 직사각형 격자를 만드는 함수\n",
        "# x0 500 구간이 200번 반복\n",
        "# x1 200 구간이 500번 반복\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "\n",
        "y_proba = log_reg.predict_proba(X_new)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"bs\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"g^\")\n",
        "\n",
        "zz = y_proba[:, 1].reshape(x0.shape)\n",
        "contour = plt.contour(x0, x1, zz, cmap=plt.cm.brg)\n",
        "\n",
        "\n",
        "left_right = np.array([2.9, 7])\n",
        "boundary = -(log_reg.coef_[0][0] * left_right + log_reg.intercept_[0]) / log_reg.coef_[0][1]\n",
        "\n",
        "plt.clabel(contour, inline=1, fontsize=12)\n",
        "plt.plot(left_right, boundary, \"k--\", linewidth=3)\n",
        "plt.text(3.5, 1.5, \"Not Iris virginica\", fontsize=14, color=\"b\", ha=\"center\")\n",
        "plt.text(6.5, 2.3, \"Iris virginica\", fontsize=14, color=\"g\", ha=\"center\")\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.axis([2.9, 7, 0.8, 2.7])\n",
        "save_fig(\"logistic_regression_contour_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R6PnTdkRgl0"
      },
      "source": [
        "**식 4-20: 소프트맥스 함수**\n",
        "\n",
        "$\n",
        "\\hat{p}_k = \\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}\n",
        "$\n",
        "\n",
        "**식 4-22: 크로스 엔트로피 비용 함수**\n",
        "\n",
        "$\n",
        "J(\\boldsymbol{\\Theta}) = - \\dfrac{1}{m}\\sum\\limits_{i=1}^{m}\\sum\\limits_{k=1}^{K}{y_k^{(i)}\\log\\left(\\hat{p}_k^{(i)}\\right)}\n",
        "$\n",
        "\n",
        "**식 4-23: 클래스 k에 대한 크로스 엔트로피의 그레이디언트 벡터**\n",
        "\n",
        "$\n",
        "\\nabla_{\\boldsymbol{\\theta}^{(k)}} \\, J(\\boldsymbol{\\Theta}) = \\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{ \\left ( \\hat{p}^{(i)}_k - y_k^{(i)} \\right ) \\mathbf{x}^{(i)}}\n",
        "$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6yKXf9ORgl1"
      },
      "source": [
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 꽃잎 너비\n",
        "y = iris[\"target\"]\n",
        "\n",
        "softmax_reg = LogisticRegression(multi_class=\"multinomial\",solver=\"lbfgs\", C=10, random_state=42)\n",
        "softmax_reg.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imfA72Sp67h2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQWUycy3Rgl1"
      },
      "source": [
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(0, 8, 500).reshape(-1, 1),\n",
        "        np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "\n",
        "\n",
        "y_proba = softmax_reg.predict_proba(X_new)\n",
        "y_predict = softmax_reg.predict(X_new)\n",
        "\n",
        "zz1 = y_proba[:, 1].reshape(x0.shape)\n",
        "zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris virginica\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris versicolor\")\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris setosa\")\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0']) # 확률값에 따라 색깔을 다르게 줌\n",
        "\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap) \n",
        "contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg) # 등고선\n",
        "plt.clabel(contour, inline=1, fontsize=12)\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.legend(loc=\"center left\", fontsize=14)\n",
        "plt.axis([0, 7, 0, 3.5])\n",
        "save_fig(\"softmax_regression_contour_plot\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQzElSL5Rgl1"
      },
      "source": [
        "softmax_reg.predict([[5, 2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvrwjha4Rgl1"
      },
      "source": [
        "softmax_reg.predict_proba([[5, 2]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGmt1zMCRgl1"
      },
      "source": [
        "# 연습문제 해답"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy0jhXODRgl1"
      },
      "source": [
        "## 1. to 11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNXKKH5hRgl1"
      },
      "source": [
        "부록 A를 참고하세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNikcgoqRgl1"
      },
      "source": [
        "## 12. 조기 종료를 사용한 배치 경사 하강법으로 소프트맥스 회귀 구현하기\n",
        "(사이킷런을 사용하지 않고)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONFKGdY1Rgl1"
      },
      "source": [
        "먼저 데이터를 로드합니다. 앞서 사용했던 Iris 데이터셋을 재사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnXCUrhdRgl1"
      },
      "source": [
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 꽃잎 넓이\n",
        "y = iris[\"target\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwpX_coGRgl1"
      },
      "source": [
        "모든 샘플에 편향을 추가합니다 ($x_0 = 1$):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbPqX8C_Rgl1"
      },
      "source": [
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw7AqZi6Rgl1"
      },
      "source": [
        "결과를 일정하게 유지하기 위해 랜덤 시드를 지정합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSe5Ky_1Rgl2"
      },
      "source": [
        "np.random.seed(2042)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz3fpel4Rgl2"
      },
      "source": [
        "데이터셋을 훈련 세트, 검증 세트, 테스트 세트로 나누는 가장 쉬운 방법은 사이킷런의 `train_test_split()` 함수를 사용하는 것입니다. 하지만 이 연습문제의 목적은 직접 만들어 보면서 알고리즘을 이해하는 것이므로 다음과 같이 수동으로 나누어 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UUgyc2xRgl2"
      },
      "source": [
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "total_size = len(X_with_bias)\n",
        "\n",
        "test_size = int(total_size * test_ratio)\n",
        "validation_size = int(total_size * validation_ratio)\n",
        "train_size = total_size - test_size - validation_size\n",
        "\n",
        "rnd_indices = np.random.permutation(total_size)\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7hh-_1xRgl2"
      },
      "source": [
        "타깃은 클래스 인덱스(0, 1 그리고 2)이지만 소프트맥스 회귀 모델을 훈련시키기 위해 필요한 것은 타깃 클래스의 확률입니다. 각 샘플에서 확률이 1인 타깃 클래스를 제외한 다른 클래스의 확률은 0입니다(다른 말로하면 주어진 샘플에 대한 클래스 확률이 원-핫 벡터입니다). 클래스 인덱스를 원-핫 벡터로 바꾸는 간단한 함수를 작성하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOlRqFLWRgl2"
      },
      "source": [
        "def to_one_hot(y):\n",
        "    n_classes = y.max() + 1\n",
        "    m = len(y)\n",
        "    Y_one_hot = np.zeros((m, n_classes))\n",
        "    Y_one_hot[np.arange(m), y] = 1\n",
        "    return Y_one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JM8wPjBRgl2"
      },
      "source": [
        "10개 샘플만 넣어 이 함수를 테스트해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7AKYeNuRgl2"
      },
      "source": [
        "y_train[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVJo4vo4Rgl2"
      },
      "source": [
        "to_one_hot(y_train[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3zewP95Rgl2"
      },
      "source": [
        "잘 되네요, 이제 훈련 세트와 테스트 세트의 타깃 클래스 확률을 담은 행렬을 만들겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfa5A0dTRgl2"
      },
      "source": [
        "Y_train_one_hot = to_one_hot(y_train)\n",
        "Y_valid_one_hot = to_one_hot(y_valid)\n",
        "Y_test_one_hot = to_one_hot(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pW24W6XRgl2"
      },
      "source": [
        "이제 소프트맥스 함수를 만듭니다. 다음 공식을 참고하세요:\n",
        "\n",
        "$\\sigma\\left(\\mathbf{s}(\\mathbf{x})\\right)_k = \\dfrac{\\exp\\left(s_k(\\mathbf{x})\\right)}{\\sum\\limits_{j=1}^{K}{\\exp\\left(s_j(\\mathbf{x})\\right)}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dUjl9j4Rgl2"
      },
      "source": [
        "def softmax(logits):\n",
        "    exps = np.exp(logits)\n",
        "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
        "    return exps / exp_sums"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nGAWJkfRgl2"
      },
      "source": [
        "훈련을 위한 준비를 거의 마쳤습니다. 입력과 출력의 개수를 정의합니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPk8ujRfRgl3"
      },
      "source": [
        "n_inputs = X_train.shape[1] # == 3 (특성 2개와 편향)\n",
        "n_outputs = len(np.unique(y_train))   # == 3 (3개의 붓꽃 클래스)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzlkouVORgl3"
      },
      "source": [
        "이제 좀 복잡한 훈련 파트입니다! 이론적으로는 간단합니다. 그냥 수학 공식을 파이썬 코드로 바꾸기만 하면 됩니다. 하지만 실제로는 꽤 까다로운 면이 있습니다. 특히, 항이나 인덱스의 순서가 뒤섞이기 쉽습니다. 제대로 작동할 것처럼 코드를 작성했더라도 실제 제대로 계산하지 못합니다. 확실하지 않을 때는 각 항의 크기를 기록하고 이에 상응하는 코드가 같은 크기를 만드는지 확인합니다. 각 항을 독립적으로 평가해서 출력해 보는 것도 좋습니다. 사실 사이킷런에 이미 잘 구현되어 있기 때문에 이렇게 할 필요는 없습니다. 하지만 직접 만들어 보면 어떻게 작동하는지 이해하는데 도움이 됩니다.\n",
        "\n",
        "구현할 공식은 비용함수입니다:\n",
        "\n",
        "$J(\\mathbf{\\Theta}) =\n",
        "- \\dfrac{1}{m}\\sum\\limits_{i=1}^{m}\\sum\\limits_{k=1}^{K}{y_k^{(i)}\\log\\left(\\hat{p}_k^{(i)}\\right)}$\n",
        "\n",
        "그리고 그레이디언트 공식입니다:\n",
        "\n",
        "$\\nabla_{\\mathbf{\\theta}^{(k)}} \\, J(\\mathbf{\\Theta}) = \\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{ \\left ( \\hat{p}^{(i)}_k - y_k^{(i)} \\right ) \\mathbf{x}^{(i)}}$\n",
        "\n",
        "$\\hat{p}_k^{(i)} = 0$이면 $\\log\\left(\\hat{p}_k^{(i)}\\right)$를 계산할 수 없습니다. `nan` 값을 피하기 위해 $\\log\\left(\\hat{p}_k^{(i)}\\right)$에 아주 작은 값 $\\epsilon$을 추가하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duFj_3LXRgl3"
      },
      "source": [
        "eta = 0.01\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    if iteration % 500 == 0:\n",
        "        loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "        print(iteration, loss)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error)\n",
        "    Theta = Theta - eta * gradients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca3iz_qKRgl3"
      },
      "source": [
        "바로 이겁니다! 소프트맥스 모델을 훈련시켰습니다. 모델 파라미터를 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxAmBqEGRgl3"
      },
      "source": [
        "Theta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI9leu5kRgl3"
      },
      "source": [
        "검증 세트에 대한 예측과 정확도를 확인해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3svjBSPMRgl3"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFZxnpphRgl3"
      },
      "source": [
        "와우, 이 모델이 매우 잘 작동하는 것 같습니다. 연습을 위해서 $\\ell_2$ 규제를 조금 추가해 보겠습니다. 다음 코드는 위와 거의 동일하지만 손실에 $\\ell_2$ 페널티가 추가되었고 그래디언트에도 항이 추가되었습니다(`Theta`의 첫 번째 원소는 편향이므로 규제하지 않습니다). 학습률 `eta`도 증가시켜 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhYb12dRRgl3"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1  # 규제 하이퍼파라미터\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "        loss = xentropy_loss + alpha * l2_loss\n",
        "        print(iteration, loss)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF2zorvnRgl3"
      },
      "source": [
        "추가된 $\\ell_2$ 페널티 때문에 이전보다 손실이 조금 커보이지만 더 잘 작동하는 모델이 되었을까요? 확인해 보죠:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G87kXKIARgl3"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60my_-IORgl4"
      },
      "source": [
        "와우, 완벽한 정확도네요! 운이 좋은 검증 세트일지 모르지만 잘 된 것은 맞습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvfiDZ2MRgl4"
      },
      "source": [
        "이제 조기 종료를 추가해 보죠. 이렇게 하려면 매 반복에서 검증 세트에 대한 손실을 계산해서 오차가 증가하기 시작할 때 멈춰야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaIktWvJRgl4"
      },
      "source": [
        "eta = 0.1 \n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1  # 규제 하이퍼파라미터\n",
        "best_loss = np.infty\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    xentropy_loss = -np.mean(np.sum(Y_valid_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:\n",
        "        print(iteration - 1, best_loss)\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQWbP1H-Rgl4"
      },
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEWeVQrVRgl4"
      },
      "source": [
        "여전히 완벽하지만 더 빠릅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYz_htkBRgl4"
      },
      "source": [
        "이제 전체 데이터셋에 대한 모델의 예측을 그래프로 나타내 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfFPs2QRRgl4"
      },
      "source": [
        "x0, x1 = np.meshgrid(\n",
        "        np.linspace(0, 8, 500).reshape(-1, 1),\n",
        "        np.linspace(0, 3.5, 200).reshape(-1, 1),\n",
        "    )\n",
        "X_new = np.c_[x0.ravel(), x1.ravel()]\n",
        "X_new_with_bias = np.c_[np.ones([len(X_new), 1]), X_new]\n",
        "\n",
        "logits = X_new_with_bias.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "zz1 = Y_proba[:, 1].reshape(x0.shape)\n",
        "zz = y_predict.reshape(x0.shape)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(X[y==2, 0], X[y==2, 1], \"g^\", label=\"Iris virginica\")\n",
        "plt.plot(X[y==1, 0], X[y==1, 1], \"bs\", label=\"Iris versicolor\")\n",
        "plt.plot(X[y==0, 0], X[y==0, 1], \"yo\", label=\"Iris setosa\")\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
        "\n",
        "plt.contourf(x0, x1, zz, cmap=custom_cmap)\n",
        "contour = plt.contour(x0, x1, zz1, cmap=plt.cm.brg)\n",
        "plt.clabel(contour, inline=1, fontsize=12)\n",
        "plt.xlabel(\"Petal length\", fontsize=14)\n",
        "plt.ylabel(\"Petal width\", fontsize=14)\n",
        "plt.legend(loc=\"upper left\", fontsize=14)\n",
        "plt.axis([0, 7, 0, 3.5])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cTcAZGvRgl4"
      },
      "source": [
        "이제 테스트 세트에 대한 모델의 최종 정확도를 측정해 보겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRSsweKqRgl4"
      },
      "source": [
        "logits = X_test.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_test)\n",
        "accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QS83-JYYRgl4"
      },
      "source": [
        "완벽했던 최종 모델의 성능이 조금 떨어졌습니다. 이런 차이는 데이터셋이 작기 때문일 것입니다. 훈련 세트와 검증 세트, 테스트 세트를 어떻게 샘플링했는지에 따라 매우 다른 결과를 얻을 수 있습니다. 몇 번 랜덤 시드를 바꾸고 이 코드를 다시 실행해 보면 결과가 달라지는 것을 확인할 수 있습니다."
      ]
    }
  ]
}